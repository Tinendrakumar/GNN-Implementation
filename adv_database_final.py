# -*- coding: utf-8 -*-
"""Adv_database_FINAL.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bDHWq_6JtmkIIFJknezPaUkuyeSJ-j0E

###Install required libraries
"""

!pip install torch_geometric

"""##Training the models GCN, Graphsage and GAT for Cora dataset"""

import argparse
import torch
from sklearn.metrics import classification_report
from torch_geometric.datasets import TUDataset
from torch_geometric.datasets import Planetoid
from torch_geometric.data import DataLoader
import torch_geometric.nn as pyg_nn
from matplotlib import pyplot as plt
import models
import utils
import os

import sys
sys.argv=['']
del sys

os.environ["CUDA_VISIBLE_DEVICES"] = "0"

# get the device to run
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

def arg_parse():
    parser = argparse.ArgumentParser(description='GNN arguments.')
    utils.parse_optimizer(parser)

    parser.add_argument('--model_type', type=str, help='Type of GNN model.')
    parser.add_argument('--batch_size', type=int, help='Training batch size')
    parser.add_argument('--num_layers', type=int, help='Number of graph conv layers')
    parser.add_argument('--hidden_dim', type=int, help='Training hidden size')
    parser.add_argument('--dropout', type=float, help='Dropout rate')
    parser.add_argument('--epochs', type=int, help='Number of training epochs')
    parser.add_argument('--dataset', type=str, help='Dataset')

    parser.set_defaults(
        model_type='GCN',
        dataset='cora',
        num_layers=2,
        batch_size=32,
        hidden_dim=16,
        dropout=0.5,
        epochs=200,
        opt='adam',  # opt_parser
        opt_scheduler='none',
        weight_decay=0,
        lr=0.01)

    return parser.parse_args()


def train(dataset, task, args):
    if task == 'graph':
        data_size = len(dataset)
        loader = DataLoader(dataset[:int(data_size * 0.8)], batch_size=args.batch_size, shuffle=True)
        test_loader = DataLoader(dataset[int(data_size * 0.8):], batch_size=args.batch_size, shuffle=True)
    elif task == 'node':
        test_loader = loader = DataLoader(dataset, batch_size=args.batch_size, shuffle=True)
    else:
        raise RuntimeError('Unknown task')

    # build model
    model = models.GNNStack(dataset.num_node_features, args.hidden_dim, dataset.num_classes, args, task=task)
    model.to(device)
    scheduler, opt = utils.build_optimizer(args, model.parameters())

    # train
    vals = []
    tests = []
    best_validation_acc = 0
    test_acc = 0
    early_stop = 1e9
    stop_cnt = 0

    for epoch in range(1, args.epochs + 1):
        total_loss = 0
        model.train()
        for batch in loader:
            batch.to(device)
            opt.zero_grad()
            pred = model(batch)
            label = batch.y
            if task == 'node':
                pred = pred[batch.train_mask]
                label = label[batch.train_mask]
            loss = model.loss(pred, label)
            loss.backward()
            opt.step()
            total_loss += loss.item() * batch.num_graphs
        total_loss /= len(loader.dataset)

        validation_acc, test_acc = test(loader, model, is_validation=True), test(loader, model)
        vals.append(validation_acc)
        tests.append(test_acc)

        if validation_acc > best_validation_acc:
            best_validation_acc = validation_acc
            test_acc = test_acc
            stop_cnt = 0
        else:
            stop_cnt += 1
        print("Epoch {}. Loss: {:.4f}. Validation accuracy: {:.4f}. Test accuracy: {:.4f}".format(epoch, total_loss, validation_acc, test_acc))
        if stop_cnt >= early_stop:
            break

    print('Final validation set accuracy {0}, test set accuracy {1}'.format(best_validation_acc, test_acc))
    return list(range(1, args.epochs + 1)), vals




def test(loader, model, is_validation=False):
    model.eval()

    correct = 0
    for data in loader:
        data.to(device)
        with torch.no_grad():
            pred = model(data).max(dim=1)[1]
            label = data.y

        if model.task == 'node':
            mask = data.val_mask.cpu() if is_validation else data.test_mask.cpu()
            pred = pred[mask].cpu()
            label = data.y[mask].cpu()

        correct += pred.eq(label).sum().item()

    if model.task == 'graph':
        total = len(loader.dataset)
    else:
        total = 0
        for data in loader.dataset:
            total += torch.sum(data.test_mask).item() if not is_validation else torch.sum(data.val_mask).item()
    return correct / total

def main():
    args = arg_parse()

    args.dataset = "cora"
    args.dropout = 0
    args.epochs = 650

    if args.dataset == 'enzymes':
        dataset = TUDataset(root='/tmp/ENZYMES', name='ENZYMES')
        task = 'graph'
    elif args.dataset == 'cora':
        dataset = Planetoid(root='/tmp/Cora', name='Cora')
        task = 'node'
    print("Number of nodes in validation set of cora dataset: ", dataset[0].test_mask.sum().item())
    print("")
    print("******************GCN MODEL*********************")
    gcn_epoch, gcn_vals = train(dataset, task, args)
    plt.plot(gcn_epoch, gcn_vals, label="GCN", color="green")

    print("")
    print("******************GRAPHSAGE MODEL*********************")
    args.model_type = "GraphSage"
    args.hidden_dim = 256
    gcn_epoch, gcn_vals = train(dataset, task, args)
    plt.plot(gcn_epoch, gcn_vals, label="GraphSage", color="blue")

    print("")
    print("******************GAT MODEL*********************")
    args.model_type = "GAT"
    args.hidden_dim = 16
    gcn_epoch, gcn_vals = train(dataset, task, args)

    plt.plot(gcn_epoch, gcn_vals, label="GAT", color="black")
    plt.title("Accuracy VS Epochs on Cora Dataset")
    plt.xlabel("Epochs")
    plt.ylabel("Validation Accuracy")
    plt.legend()
    plt.grid(True)
    plt.show()

if __name__ == '__main__':
    main()

"""##Number of Nodes for Cora dataset"""

print("CORA dataset:")
# Load the CORA dataset and print information about the test set
cora = Planetoid(root='data', name='Cora')
print("Number of nodes in cora dataset: ", cora.data.num_nodes)
test_cora = cora.data.test_mask
print("Number of nodes in the test set of CORA:", test_cora.sum().item())

"""##Number of graphs for Enzymes dataset"""

print("ENZYMES dataset:")
# Load the ENZYMES dataset
Enzymes = TUDataset(root='data', name='ENZYMES')
print(f"Total Number of graphs in Enzymes test set: {len(Enzymes)}")
test_dataset1 = Enzymes[int(len(Enzymes) * 0.8):]
print(f"Number of graphs in Enzymes test set: {len(test_dataset1)}")

"""##Training the models GCN, Graphsage and GAT for Enzymes dataset"""

import argparse
import torch
from sklearn.metrics import classification_report
from torch_geometric.datasets import TUDataset
from torch_geometric.datasets import Planetoid
from torch_geometric.data import DataLoader
import torch_geometric.nn as pyg_nn
from matplotlib import pyplot as plt
import models
import utils
import os

import sys
sys.argv=['']
del sys

os.environ["CUDA_VISIBLE_DEVICES"] = "0"

# get the device to run
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

def arg_parse():
    parser = argparse.ArgumentParser(description='GNN arguments.')
    utils.parse_optimizer(parser)

    parser.add_argument('--model_type', type=str, help='Type of GNN model.')
    parser.add_argument('--batch_size', type=int, help='Training batch size')
    parser.add_argument('--num_layers', type=int, help='Number of graph conv layers')
    parser.add_argument('--hidden_dim', type=int, help='Training hidden size')
    parser.add_argument('--dropout', type=float, help='Dropout rate')
    parser.add_argument('--epochs', type=int, help='Number of training epochs')
    parser.add_argument('--dataset', type=str, help='Dataset')

    parser.set_defaults(
        model_type='GCN',
        dataset='cora',
        num_layers=2,
        batch_size=32,
        hidden_dim=16,
        dropout=0.5,
        epochs=200,
        opt='adam',  # opt_parser
        opt_scheduler='none',
        weight_decay=0,
        lr=0.01)

    return parser.parse_args()


def train(dataset, task, args):
    if task == 'graph':
        data_size = len(dataset)
        loader = DataLoader(dataset[:int(data_size * 0.8)], batch_size=args.batch_size, shuffle=True)
        test_loader = DataLoader(dataset[int(data_size * 0.8):], batch_size=args.batch_size, shuffle=True)
    elif task == 'node':
        test_loader = loader = DataLoader(dataset, batch_size=args.batch_size, shuffle=True)
    else:
        raise RuntimeError('Unknown task')

    # build model
    model = models.GNNStack(dataset.num_node_features, args.hidden_dim, dataset.num_classes, args, task=task)
    model.to(device)
    scheduler, opt = utils.build_optimizer(args, model.parameters())

    # train
    vals = []
    tests = []
    best_validation_acc = 0
    test_acc = 0
    early_stop = 1e9
    stop_cnt = 0

    for epoch in range(1, args.epochs + 1):
        total_loss = 0
        model.train()
        for batch in loader:
            batch.to(device)
            opt.zero_grad()
            pred = model(batch)
            label = batch.y
            if task == 'node':
                pred = pred[batch.train_mask]
                label = label[batch.train_mask]
            loss = model.loss(pred, label)
            loss.backward()
            opt.step()
            total_loss += loss.item() * batch.num_graphs
        total_loss /= len(loader.dataset)

        validation_acc, test_acc = test(loader, model, is_validation=True), test(loader, model)
        vals.append(validation_acc)
        tests.append(test_acc)

        if validation_acc > best_validation_acc:
            best_validation_acc = validation_acc
            test_acc = test_acc
            stop_cnt = 0
        else:
            stop_cnt += 1
        print("Epoch {}. Loss: {:.4f}. Validation accuracy: {:.4f}. Test accuracy: {:.4f}".format(epoch, total_loss, validation_acc, test_acc))
        if stop_cnt >= early_stop:
            break

    print('Final validation set accuracy {0}, test set accuracy {1}'.format(best_validation_acc, test_acc))
    return list(range(1, args.epochs + 1)), vals




def test(loader, model, is_validation=False):
    model.eval()

    correct = 0
    for data in loader:
        data.to(device)
        with torch.no_grad():
            pred = model(data).max(dim=1)[1]
            label = data.y

        if model.task == 'node':
            mask = data.val_mask.cpu() if is_validation else data.test_mask.cpu()
            pred = pred[mask].cpu()
            label = data.y[mask].cpu()

        correct += pred.eq(label).sum().item()

    if model.task == 'graph':
        total = len(loader.dataset)
    else:
        total = 0
        for data in loader.dataset:
            total += torch.sum(data.test_mask).item() if not is_validation else torch.sum(data.val_mask).item()
    return correct / total

def main():
    args = arg_parse()

    args.dataset = "enzymes"
    args.dropout = 0
    args.epochs = 650

    if args.dataset == 'enzymes':
        dataset = TUDataset(root='/tmp/ENZYMES', name='ENZYMES')
        task = 'graph'
    elif args.dataset == 'cora':
        dataset = Planetoid(root='/tmp/Cora', name='Cora')
        task = 'node'
    # print("Number of nodes in validation set of cora dataset: ", dataset[0].test_mask.sum().item())
    print("")
    print("******************GCN MODEL*********************")
    gcn_epoch, gcn_vals = train(dataset, task, args)
    plt.plot(gcn_epoch, gcn_vals, label="GCN", color="green")

    print("")
    print("******************GRAPHSAGE MODEL*********************")
    args.model_type = "GraphSage"
    args.hidden_dim = 256
    gcn_epoch, gcn_vals = train(dataset, task, args)
    plt.plot(gcn_epoch, gcn_vals, label="GraphSage", color="blue")

    print("")
    print("******************GAT MODEL*********************")
    args.model_type = "GAT"
    args.hidden_dim = 16
    gcn_epoch, gcn_vals = train(dataset, task, args)

    plt.plot(gcn_epoch, gcn_vals, label="GAT", color="black")
    plt.title("Accuracy VS Epochs on Cora Dataset")
    plt.xlabel("Epochs")
    plt.ylabel("Validation Accuracy")
    plt.legend()
    plt.grid(True)
    plt.show()

if __name__ == '__main__':
    main()

"""##Question 6:

GCN, GraphSage, and GAT are all popular graph neural network (GNN) models that can be used for a variety of graph-related tasks, including node classification and graph classification. Each of these models has its unique architecture and learning mechanism, which leads to different performance on different tasks. Here is a brief description of the performance differences between GCN, GraphSage, and GAT on both tasks. I will describe the performance differences between these models on two popular benchmark graph datasets, Cora and Enzymes.

**Cora Dataset**

The Cora dataset consists of scientific publications, where nodes represent documents and edges represent citations. The task is to classify documents into one of seven categories.

| Model | Cora Accuracy |
| --- | --- |
| GCN | 78% |
| GraphSage |74.8%  |
| GAT | 79.2% |

From the above table, we can see that GCN and GAT outperform GraphSage on the Cora dataset. GCN achieves an accuracy of 78%, while GAT achieves an accuracy of 79%, which is the best among the three models.

**Enzymes Dataset**

The Enzymes dataset consists of protein structures, where nodes represent amino acids and edges represent interactions between them. The task is to classify enzymes into one of six classes based on their structural properties.

| Model | Enzymes |
| --- | --- |
| GCN | 38.7% |
| GraphSage | 73% |
| GAT | 45% |

From the above table, we can see that Graphsage outperforms GCN and GAT on the Enzymes dataset. Graphsage achieves a score of 73%, which is the best among the three models.

In summary, the performance of GCN, GraphSage, and GAT can vary depending on the specific task and dataset. However, in general, GAT tends to perform the best on node classification tasks, while GraphSage tends to perform the best on graph classification tasks. GCN is a good performer on both tasks, but it may struggle with capturing higher-order graph structures and global graph structure compared to the other two models.
"""